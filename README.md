## Data Engineering Projects

## Level's of Skill for each Project

**Blue** :

* All code follows best practices and was run through a linter   

* Classes and Functions are used when appropriate  

* Project is organized into modules logically  

* project is a pypi project  

**Purple**:  


* code is testable without interacting with external dependencies

* code is tests with reasonable code coverage.

* code has intergration tests for external dependencies. 

* project uses has tests for all the infrastructure  

 
**Brown** :

* project uses infrastructure as code (terraform or Cloudwatch)  

* project uses Docker for local development 

* code uses fakes (mocks and stubs)

* code relies on abstraction's (interfaces).

* project uses a CI/CD process using something like Jenkins  

* project uses concurrency when appropriate  
  
  
## Projects     
  
1. [Merge pipeline DB and API](https://github.com/bclipp/data_engineering_projects/tree/master/project01)
2. [Streaming PostGresql CDC to S3](https://github.com/bclipp/data_engineering_projects/tree/master/project02)   
3. [Data Modeling in PostgreSQL](https://github.com/bclipp/data_engineering_projects/tree/master/project03)  
4. [Data Modeling in Cassandra](https://github.com/bclipp/data_engineering_projects/tree/master/project04)  
5. [Data Warehouse](https://github.com/bclipp/data_engineering_projects/tree/master/project05)   
6. [Spark DataLake](https://github.com/bclipp/data_engineering_projects/tree/master/project06)
7. REST API crud app
8. Grps crud  app
9. Kafka Project
10. Data Modeling in MongoDB
11. Data Modeling in Elasticsearch
12.
